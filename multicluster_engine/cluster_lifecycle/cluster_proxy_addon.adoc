[#cluster-proxy-addon]
= Using cluster proxy add-ons

In some environments, a managed cluster is behind a firewall and cannot be accessed directly by the hub cluster. To gain access, you can set up a proxy add-on to access the `kube-apiserver` of the managed cluster to provide a more secure connection. 

*Required access*: Editor

To configure a cluster proxy add-on for a hub cluster and a managed cluster, complete the following steps:

. Configure the `kubeconfig` file to access the managed cluster `kube-apiserver` by completing the following steps:

.. Provide a valid access token for the managed cluster. 

*Note:* : You can use the corresponding token of the service account. We use the default service account is in the default namespace.

... Export the managed cluster kubeconfig
+
----
export KUBECONFIG=<MANAGED CLUSTER KUBECONFIG>
----

... Add a role to your service account that allows it to access pods by running the following commands:
+
----
oc create role -n default test-role --verb=list,get --resource=pods 
oc create rolebinding -n default test-rolebinding --serviceaccount=default:default --role=test-role
----

... Run the following command to locate the secret of the service account token:
+
----
oc get secret -n default | grep <default-token>
----

... Run the following command to copy the token:
+
----
export MANAGED_CLUSTER_TOKEN=$(kubectl -n default get secret <default-token> -o jsonpath={.data.token} | base64 -d) 
----
+
Replace `default-token` with the name of your secret.

.. Configure the `kubeconfig` file on the {product-title-short} hub cluster.

... Export the current `kubeconfig` file on the hub cluster by running the following command:
+
----
oc config view --minify --raw=true > cluster-proxy.kubeconfig
----

... Modify the `server` file with your editor. This example uses commands when using `sed`. Run `alias sed=gsed`, if you are using OSX.
+
----
export TARGET_MANAGED_CLUSTER=<MANAGED CLUSTER NAME>

export NEW_SERVER=https://$(oc get route -n multicluster-engine cluster-proxy-addon-user -o=jsonpath='{.spec.host}')/$TARGET_MANAGED_CLUSTER

sed -i'' -e '/server:/c\    server: '"$NEW_SERVER"'' cluster-proxy.kubeconfig

export CADATA=$(oc get configmap -n openshift-service-ca kube-root-ca.crt -o=go-template='{{index .data "ca.crt"}}' | base64)

sed -i'' -e '/certificate-authority-data:/c\    certificate-authority-data: '"$CADATA"'' cluster-proxy.kubeconfig
----
+

... Delete the original user credentials by entering the following commands: 
+
----
sed -i'' -e '/client-certificate-data/d' cluster-proxy.kubeconfig
sed -i'' -e '/client-key-data/d' cluster-proxy.kubeconfig
sed -i'' -e '/token/d' cluster-proxy.kubeconfig
----

... Add the token of the service account:
+
----
sed -i'' -e '$a\    token: '"$MANAGED_CLUSTER_TOKEN"'' cluster-proxy.kubeconfig
----

. List all of the pods on the target namespace of the target managed cluster by running the following command: 
+
----
oc get pods --kubeconfig=cluster-proxy.kubeconfig -n <default> 
----
+
Replace the `default` namespace with the namespace that you want to use.

Your hub cluster is now communicating with the `kube-api` of your managed cluster. 
