[#placement-managed]
= Using ManagedClusterSets with Placement

A `Placement` resource is a namespace-scoped resource that defines a rule to select a set of `ManagedClusters` from the `ManagedClusterSets`, which are bound to the placement namespace.

**Required access**: Cluster administrator, Cluster set administrator

[#placement-overview]
== Placement overview

See the following information about how placement with managed clusters works:

* Kubernetes clusters are registered with the hub cluster as cluster-scoped `ManagedClusters`.

* The `ManagedClusters` are organized into cluster-scoped `ManagedClusterSets`.

* The `ManagedClusterSets` are bound to workload namespaces.

* The namespace-scoped `Placements` specify a portion of `ManagedClusterSets` that select a working set of the potential `ManagedClusters`.

* `Placements` filter `ManagedClusters` from the managed cluster set by using label and claim selectors.

* The placement of `ManagedClusters` can be controlled by using taints and tolerations. See xref:../cluster_lifecycle/taints_tolerations.adoc#taints-tolerations-managed[Using taints and tolerations to place managed clusters] for more information.

* `Placements` rank the clusters by the requirements and select a subset of clusters from them.

*Notes:* 

* You need to bind at least one `ManagedClusterSet` to a namespace by creating a `ManagedClusterSetBinding` in that namespace. 
* You need role-based access to `CREATE` on the virtual sub-resource of `managedclustersets/bind`.

The following content provides general information about the `Placement` API and provides examples of how to use it.

The `Placement` specification includes the following fields:

* `ClusterSets` represents the `ManagedClusterSets` from which the `ManagedClusters` are selected. 

  ** If not specified, the `ManagedClusters` is selected from the `ManagedClusterSets` that are bound to the placement namespace. 

  ** If specified, `ManagedClusters` is selected from the intersection of this set and the `ManagedClusterSets` that are bound to the placement namespace.

* `NumberOfClusters` represents the desired number of `ManagedClusters` to be selected, which meet the placement requirements. 
+
If not specified, all `ManagedClusters` that meet the placement requirements are selected.

* `Predicates` represents a slice of predicates to select `ManagedClusters` with label and claim selector. The predicates are ORed.

* `Tolerations` allow Placements to select `ManagedClusters` with matching taints.

* `PrioritizerPolicy` represents the policy of prioritizers. 

[#placement-labelselector-claimSelector]
== Placement LabelSelector and ClaimSelector

- You can select `ManagedClusters` with the `labelSelector`. See the following sample where the `labelSelector` only matches clusters with label `vendor: OpenShift`:
+
[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1beta1
kind: Placement
metadata:
  name: placement
  namespace: ns1
spec:
  predicates:
    - requiredClusterSelector:
        labelSelector:
          matchLabels:
            vendor: OpenShift

----

- You can select `ManagedClusters` with `claimSelector`. See the following sample where `claimSelector` only matches clusters with `region.open-cluster-management.io` with `us-west-1`:
+
[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1beta1
kind: Placement
metadata:
  name: placement
  namespace: ns1
spec:
  predicates:
    - requiredClusterSelector:
        claimSelector:
          matchExpressions:
            - key: region.open-cluster-management.io
              operator: In
              values:
                - us-west-1
----

- You can select `ManagedClusters` from particular `clusterSets`. See the following sample where `claimSelector` only matches `clusterSets:` `clusterset1` `clusterset2`:
+
[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1beta1
kind: Placement
metadata:
  name: placement
  namespace: ns1
spec:
  clusterSets:
    - clusterset1
    - clusterset2
  predicates:
    - requiredClusterSelector:
        claimSelector:
          matchExpressions:
            - key: region.open-cluster-management.io
              operator: In
              values:
                - us-west-1
----

- Select desired number of `ManagedClusters`. See the following sample where `numberOfClusters` is `3`:
+
[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1beta1
kind: Placement
metadata:
  name: placement
  namespace: ns1
spec:
  numberOfClusters: 3
  predicates:
    - requiredClusterSelector:
        labelSelector:
          matchLabels:
            vendor: OpenShift
        claimSelector:
          matchExpressions:
            - key: region.open-cluster-management.io
              operator: In
              values:
                - us-west-1
----

[#placement-tolerations]
== Placement Tolerations

- Select `ManagedClusters` with matching taints. 

Suppose your managed cluster has a taint as shown in the following example:

[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1
kind: ManagedCluster
metadata:
  name: cluster1
spec:
  hubAcceptsClient: true
  taints:
    - effect: NoSelect
      key: gpu
      value: "true"
      timeAdded: '2022-02-21T08:11:06Z'
----

By default, the placement cannot select this cluster unless you define tolerations, as shown in the following example:

[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1beta1
kind: Placement
metadata:
  name: placement
  namespace: ns1
spec:
  tolerations:
    - key: gpu
      value: "true"
      operator: Equal
----

- Select `ManagedClusters` with matching taints for a specified period of time.

The value of `TolerationSeconds` represents the length of time that the toleration tolerates the taint. It can be useful when a managed cluster is offline, users can make applications deployed on this cluster to be transferred to another available managed cluster after a tolerated time. The `TolerationSeconds` value can be useful by automatically transferring applications that are deployed on a cluster that goes offline to another managed cluster after a specified length of time.

For example, the managed cluster that is defined by the following example content becomes unreachable:

[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1
kind: ManagedCluster
metadata:
  name: cluster1
spec:
  hubAcceptsClient: true
  taints:
    - effect: NoSelect
      key: cluster.open-cluster-management.io/unreachable
      timeAdded: '2022-02-21T08:11:06Z'
----

If you define a placement with `TolerationSeconds` as shown in the following example, the workload is transferred to another available managed cluster after 5 minutes.

[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1alpha1
kind: Placement
metadata:
  name: placement
  namespace: ns1
spec:
  tolerations:
    - key: cluster.open-cluster-management.io/unreachable
      operator: Exists
      tolerationSeconds: 300
----

[#placement-prioritizerpolicy]
== Placement PrioritizerPolicy

- Select a cluster with the largest allocatable memory.
+
*Note:* Similar to Kubernetes https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/#node-allocatable[Node Allocatable], 'allocatable' is defined as the amount of compute resources that are available for pods on each cluster.
+
[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1beta1
kind: Placement
metadata:
  name: placement
  namespace: ns1
spec:
  numberOfClusters: 1
  prioritizerPolicy:
    configurations:
      - scoreCoordinate:
          builtIn: ResourceAllocatableMemory
----

- Select a cluster with the largest allocatable CPU and memory, and make placement sensitive to resource changes. 
+
[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1beta1
kind: Placement
metadata:
  name: placement
  namespace: ns1
spec:
  numberOfClusters: 1
  prioritizerPolicy:
    configurations:
      - scoreCoordinate:
          builtIn: ResourceAllocatableCPU
        weight: 2
      - scoreCoordinate:
          builtIn: ResourceAllocatableMemory
        weight: 2
----

- Select two clusters with the largest `addOn` score CPU ratio, and pin the placement decisions. 
+
[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1beta1
kind: Placement
metadata:
  name: placement
  namespace: ns1
spec:
  numberOfClusters: 2
  prioritizerPolicy:
    mode: Exact
    configurations:
      - scoreCoordinate:
          builtIn: Steady
        weight: 3
      - scoreCoordinate:
          type: AddOn
          addOn:
            resourceName: default
            scoreName: cpuratio
----

The following list describes the fields for `prioritizerPolicy`:
  
  ** `mode` is either `Exact`, `Additive`, or `""`, where `""` is `Additive` by default.
    
    *** In `Additive` mode, any prioritizer that is not specifically provided with configuration values is enabled with its default configurations. In the current default configuration, the _Steady_ and _Balance_ prioritizers have the weight of 1. The other prioritizers have the weight of 0. The default configurations might change in the future, which might change the prioritization. `Additive` mode does not require that you configure all of the prioritizers. 

    *** In `Exact` mode, any prioritizer that is not specifically provided with configuration values has the weight of 0. `Exact` mode requires that you input the full set of prioritizers that you want, but avoids behavior changes if the default configurations change with new releases.

  ** `configurations` represents the configuration of prioritizers.

    *** `scoreCoordinate` represents the configuration of the prioritizer and score source.

      **** `type` defines the type of the prioritizer score. Valid values are `BuiltIn`, `AddOn`, or `" "`, where `" "` is `BuiltIn` by default. When the type is `BuiltIn`, the built in prioritizer name must be specified. When the type is `AddOn`, you need to configure the score source in `AddOn`.
      
      **** `BuiltIn` defines the name of a `BuiltIn` prioritizer. The following list includes the valid `BuiltIn` prioritizer names:
         
        ***** `Balance`: Balance the decisions among the clusters.

        ***** `Steady`: Ensure the existing decision is stabilized.

        ***** `ResourceAllocatableCPU` and `ResourceAllocatableMemory`: Sort clusters based on the allocatable resources.

      **** `addOn` defines the resource name and score name. `AddOnPlacementScore` is introduced to describe `addOn` scores. See https://open-cluster-management.io/scenarios/extend-multicluster-scheduling-capabilities/[Extend the multicluster scheduling capabilities with placement] to learn more about `addOn` scores.

      ***** `resourceName` defines the resource name of the `AddOnPlacementScore`. The placement prioritizer selects the `AddOnPlacementScore` custom resource by this name.

      ***** `scoreName` defines the score name inside of the `AddOnPlacementScore`. `AddOnPlacementScore` contains a list of the score name and the score value. The `scoreName`, specifies the score to be used by the prioritizer.

    *** `weight` defines the weight of the prioritizer. The value must be in the range of [-10,10].
      
      Each prioritizer calculates an integer score of a cluster in the range of [-100, 100]. The final score of a cluster is determined by the following formula `sum(weight * prioritizer_score)`.
      
      A higher weight indicates that the prioritizer has a higher likelihood to be selected during the cluster selection. A weight of 0 indicates that the prioritizer is disabled. A cluster with a negative weight is one of the last clusters that is selected.

[#placement-decision]
== Placement decision

One or multiple `PlacementDecisions` with label `cluster.open-cluster-management.io/placement={placement name}` are created to represent the `ManagedClusters` selected by a `Placement`.

If a `ManagedCluster` is selected and added to a `PlacementDecision`, components that consume this `Placement` might apply the workload on this `ManagedCluster`. After the `ManagedCluster` is no longer selected and is removed from the `PlacementDecisions`, the workload that is applied on this `ManagedCluster` should be removed.

See the following `PlacementDecision` sample:

[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1beta1
kind: PlacementDecision
metadata:
  labels:
    cluster.open-cluster-management.io/placement: placement1
  name: placement1-kbc7q
  namespace: ns1
  ownerReferences:
    - apiVersion: cluster.open-cluster-management.io/v1beta1
      blockOwnerDeletion: true
      controller: true
      kind: Placement
      name: placement1
      uid: 05441cf6-2543-4ecc-8389-1079b42fe63e
status:
  decisions:
    - clusterName: cluster1
      reason: ''
    - clusterName: cluster2
      reason: ''
    - clusterName: cluster3
      reason: ''
----

[#addon-status]
== Add-on status

You might want to select managed clusters for your placements according to the status of the add-ons that are deployed on them. For example, you want to select a managed cluster for your placement only if there is a specific add-on that is enabled on the cluster. 

You can do this by specifying the label for the add-on, as well as its status, when you create the Placement. A label is automatically created on a `ManagedCluster` resource if an add-on is enabled on the cluster. The label is automatically removed if the add-on is disabled.

Each add-on is represented by a label in the format of `feature.open-cluster-management.io/addon-<addon_name>=<status_of_addon>`. 

Replace `addon_name` with the name of the add-on that should be enabled on the managed cluster that you want to select. 

Replace `status_of_addon` with the status that the add-on should have if the cluster is selected. The possible values of `status_of_addon` are in the following list:

* `available`: The add-on is enabled and available.
* `unhealthy`: The add-on is enabled, but the lease is not updated continuously.
* `unreachable`: The add-on is enabled, but there is no lease found for it. This can also be caused when the managed cluster is offline.

For example, an available `application-manager` add-on is represented by a label on the managed cluster that reads:

----
feature.open-cluster-management.io/addon-application-manager: available
----

See the following examples of creating placements based on add-ons and their status:

- You can create a placement that includes all managed clusters that have `application-manager` enabled on them by adding the following YAML content: 
+
[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1beta1
kind: Placement
metadata:
  name: placement1
  namespace: ns1
spec:
  predicates:
    - requiredClusterSelector:
        labelSelector:
          matchExpressions:
            - key: feature.open-cluster-management.io/addon-application-manager
              operator: Exists
----

- You can create a placement that includes all managed clusters that have `application-manager` enabled with an `available` status by adding the following YAML content: 
+
[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1beta1
kind: Placement
metadata:
  name: placement2
  namespace: ns1
spec:
  predicates:
    - requiredClusterSelector:
        labelSelector:
          matchLabels:
            "feature.open-cluster-management.io/addon-application-manager": "available"
----

- You can create a placement that includes all managed clusters that have `application-manager` disabled by adding the following YAML content: 
+
[source,yaml]
----
apiVersion: cluster.open-cluster-management.io/v1beta1
kind: Placement
metadata:
  name: placement3
  namespace: ns1
spec:
  predicates:
    - requiredClusterSelector:
        labelSelector:
          matchExpressions:
            - key: feature.open-cluster-management.io/addon-application-manager
              operator: DoesNotExist
----
