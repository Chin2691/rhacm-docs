[#creating-a-credential-for-bare-metal]
= Creating a credential for bare metal

You need a credential to use {product-title} console to deploy and manage a {ocp} cluster in a bare metal environment.

**Required access**: Edit

* <<bare_cred_prerequisites,Prerequisites>>
* <<bare-set-up-provisioner,Preparing a provisioner host>>
* <<bare_cred,Creating a credential by using the console>>
* <<bare_delete_cred,Deleting your credential>>

[#bare_cred_prerequisites]
== Prerequisites

You need the following prerequisites before creating a credential:

* A {product-title} hub cluster that is deployed.
When managing bare metal clusters, you must have the hub cluster installed on {ocp} version 4.6 or later.
* Internet access for your {product-title} hub cluster so it can create the Kubernetes cluster on your bare metal server.
* Account permissions that allow installing clusters on the bare metal infrastructure

[#bare-set-up-provisioner]
== Preparing a provisioner host

When you create a bare metal credential and cluster, you must have an available bootstrap host VM for the installation. This can be a VM or a service running KVM. You need the details of this host when you are creating the credential and the cluster. Complete the following steps to configure a provisioner host:

. Log in to the provisioner node using `ssh`.

. Create a non-root user (kni) and provide that user with sudo privileges by running the following commands:
+
----
[root@provisioner ~]# useradd kni
[root@provisioner ~]# passwd kni
[root@provisioner ~]# echo "kni ALL=(root) NOPASSWD:ALL" | tee -a /etc/sudoers.d/kni
[root@provisioner ~]# chmod 0440 /etc/sudoers.d/kni
----

. Create an ssh key for the new user by entering the following command:
+
----
[root@provisioner ~]# su - kni -c "ssh-keygen -t rsa -f /home/kni/.ssh/id_rsa -N ''"
----

. Log in as the new user on the provisioner node.
+
----
[root@provisioner ~]# su - kni
[kni@provisioner ~]$
----

. Use Red Hat Subscription Manager to register the provisioner node by entering the following commands:
+
----
[kni@provisioner ~]$ sudo subscription-manager register --username=<user> --password=<pass> --auto-attach
[kni@provisioner ~]$ sudo subscription-manager repos --enable=rhel-8-for-x86_64-appstream-rpms --enable=rhel-8-for-x86_64-baseos-rpms
----
+
For more information about Red Hat Subscription Manager, see https://access.redhat.com/documentation/en-us/red_hat_subscription_management/1/html-single/rhsm/index[Using and Configuring Red Hat Subscription Manager] in the {ocp} documentation.

. Install required packages by running the following command:
+
----
[kni@provisioner ~]$ sudo dnf install -y libvirt qemu-kvm mkisofs python3-devel jq ipmitool
----

. Modify the user to add the libvirt group to the newly created user.
+
----
[kni@provisioner ~]$ sudo usermod --append --groups libvirt <user>
----

. Restart `firewalld` and enable the `http` service by entering the following commands:
+
----
[kni@provisioner ~]$ sudo systemctl start firewalld
[kni@provisioner ~]$ sudo firewall-cmd --zone=public --add-service=http --permanent
[kni@provisioner ~]$ sudo firewall-cmd --add-port=5000/tcp --zone=libvirt  --permanent
[kni@provisioner ~]$ sudo firewall-cmd --add-port=5000/tcp --zone=public   --permanent
[kni@provisioner ~]$ sudo firewall-cmd --reload
----

. Start and enable the `libvirtd` service by entering the following commands:
+
----
[kni@provisioner ~]$ sudo systemctl start libvirtd
[kni@provisioner ~]$ sudo systemctl enable libvirtd --now
----

. Create the default storage pool and start it by entering the following commands:
+
----
[kni@provisioner ~]$ sudo virsh pool-define-as --name default --type dir --target /var/lib/libvirt/images
[kni@provisioner ~]$ sudo virsh pool-start default
[kni@provisioner ~]$ sudo virsh pool-autostart default
----

. Configure networking.
+
* _Provisioning Network (IPv4 address)_
+
----
[kni@provisioner ~]$ sudo nohup bash -c """
    nmcli con down "$PROV_CONN"
    nmcli con delete "$PROV_CONN"
    # RHEL 8.1 appends the word "System" in front of the connection, delete in case it exists
    nmcli con down "System $PROV_CONN"
    nmcli con delete "System $PROV_CONN"
    nmcli connection add ifname provisioning type bridge con-name provisioning
    nmcli con add type bridge-slave ifname "$PROV_CONN" master provisioning
    nmcli connection modify provisioning ipv4.addresses 172.22.0.1/24 ipv4.method manual
    nmcli con down provisioning
    nmcli con up provisioning"""
----
+
The ssh connection might disconnect after completing this step.
+
The IPv4 address may be any address as long as it is not routable via the baremetal network.
+
* _Provisioning Network (IPv6 address)_
+
----
[kni@provisioner ~]$ sudo nohup bash -c """
    nmcli con down "$PROV_CONN"
    nmcli con delete "$PROV_CONN"
    # RHEL 8.1 appends the word "System" in front of the connection, delete in case it exists
    nmcli con down "System $PROV_CONN"
    nmcli con delete "System $PROV_CONN"
    nmcli connection add ifname provisioning type bridge con-name provisioning
    nmcli con add type bridge-slave ifname "$PROV_CONN" master provisioning
    nmcli connection modify provisioning ipv6.addresses fd00:1101::1/64 ipv6.method manual
    nmcli con down provisioning
    nmcli con up provisioning"""
----
+
The ssh connection might disconnect after completing this step.
+
The IPv6 address can be any address as long as it is not routable using the baremetal network.
+
Ensure that UEFI is enabled and UEFI PXE settings are set to the IPv6 protocol when using IPv6 addressing.

. Reconnect to the provisioner node by using `ssh` (if required).
+
----
# ssh kni@provisioner.<cluster-name>.<domain>
----

. Verify the connection bridges have been correctly created.
+
----
[kni@provisioner ~]$ nmcli con show
----
+
Your returned results resemble the following content:
+
[frame=none,grid=none,cols="15%,60%,5%,10%"]
|====
| NAME | UUID | TYPE | DEVICE
| baremetal | 4d5133a5-8351-4bb9-bfd4-3af264801530 | bridge | baremetal
| provisioning | 43942805-017f-4d7d-a2c2-7cb3324482ed | bridge | provisioning
| virbr0 | d9bca40f-eee1-410b-8879-a2d4bb0465e7 | bridge | virbr0
| bridge-worker-eno1 | 76a8ed50-c7e5-4999-b4f6-6d9014dd0812 | ethernet | eno1
| bridge-worker-eno2 | f31c3353-54b7-48de-893a-02d2b34c4736 | ethernet | eno2
|====

. Create a pull-secret.txt file.
+
----
[kni@provisioner ~]$ vim pull-secret.txt
----
+
.. In a web browser, navigate to https://console.redhat.com/openshift/install/metal/user-provisioned[Install OpenShift on Bare Metal with user-provisioned infrastructure], and scroll down to the _Downloads_ section. 
.. Click *Copy pull secret*. 
.. Paste the contents into the `pull-secret.txt` file and save the contents in the home directory of the kni user. 

You are ready to create your bare metal cluster. 

[#bare_cred]
== Creating a credential by using the console

To create a credential from the {product-title} console, complete the following steps:

. From the navigation menu, navigate to *Credentials*. Existing credentials are displayed.

. Select *Add credential*.
. Select *Bare metal* as your provider.
. Add a name for your credential.
. Select a namespace for your credential from the list.
+
*Tip:* Create a namespace specifically to host your credentials, both for convenience and added security.

. You can optionally add a _Base DNS domain_ for your credential. If you add the base DNS domain to the credential, it is automatically populated in the correct field when you create a cluster with this credential.
. Add your _libvirt URI_. The libvirt URI is from your VM or service that is running KVM that you are using for your bootstrap node.
See https://libvirt.org/uri.html[Connection URIs] for more information.
. Add a list of your SSH known hosts.
. Enter your _Red Hat OpenShift pull secret_.
You can download your pull secret from https://cloud.redhat.com/openshift/install/pull-secret[Pull secret].
. Add your _SSH private key_ and your _SSH public key_ so you can access the cluster.
You can use an existing key, or use a key generation program to create a new one.
See https://access.redhat.com/documentation/en-us/openshift_container_platform/4.6/html/installing_on_bare_metal/installing-on-bare-metal#ssh-agent-using_installing-bare-metal[Generating an SSH private key and adding it to the agent] for more information about how to generate a key.
. For disconnected installations only: Complete the fields in the *Configuration for disconnected installation* subsection with the required information:
+
* _Image registry mirror_: This value contains the disconnected registry path. The path contains the hostname, port, and repository path to all of the installation images for disconnected installations. Example: `repository.com:5000/openshift/ocp-release`.
+
The path creates an image content source policy mapping in the `install-config.yaml` to the {ocp} release images. As an example, `repository.com:5000` produces this `imageContentSource` content:
+
----
imageContentSources:
- mirrors:
  - registry.example.com:5000/ocp4
  source: quay.io/openshift-release-dev/ocp-release-nightly
- mirrors:
  - registry.example.com:5000/ocp4
  source: quay.io/openshift-release-dev/ocp-release
- mirrors:
  - registry.example.com:5000/ocp4
  source: quay.io/openshift-release-dev/ocp-v4.0-art-dev
----
* _Bootstrap OS image_: This value contains the URL to the image to use for the bootstrap machine.
* _Cluster OS image_: This value contains the URL to the image to use for {ocp} cluster machines. 
* _Additional trust bundle_: This value provides the contents of the certificate file that is required to access the mirror registry.
+
*Note:* If you are deploying managed clusters from a hub that is in a disconnected environment, and want them to be automatically imported post install, add an Image Content Source Policy to the `install-config.yaml` file by using the `YAML` editor. A sample entry is shown in the following example: 
+
----
imageContentSources:
- mirrors:
  - registry.example.com:5000/rhacm2
  source: registry.redhat.io/rhacm2
----

. Click *Create*.
. Review the new credential information, then click *Add*. When you add the credential, it is added to the list of credentials.

You can create a cluster that uses this credential by completing the steps in link:../clusters/create_bare.adoc#creating-a-cluster-on-bare-metal[Creating a cluster on bare metal].

[#bare_delete_cred]
== Deleting your credential

When you are no longer managing a cluster that is using a credential, delete the credential to protect the information in the credential.

. From the navigation menu, navigate to *Credentials*.
. Select the options menu for the credential that you want to delete.
. Select *Delete credential*.
